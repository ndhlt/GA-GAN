{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29834d4f-6da9-4ce9-b8b1-257b42d31104",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e767ade-2a79-48c7-b348-ed10f70e83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "from torchvision.transforms import Resize\n",
    "from itertools import combinations, product\n",
    "from pathlib import Path\n",
    "\n",
    "from core.uda_models import uda_models\n",
    "from core.utils.common import mixing_noise\n",
    "from core.utils.reading_weights import read_weights\n",
    "from core.utils.example_utils import (\n",
    "    to_im, Inferencer, \n",
    "    vstack_with_lines, \n",
    "    hstack_with_lines, \n",
    "    insert_image\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from draw_util import IdentityEditor, StyleEditor, morph_g_ema, weights, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1171e-1bb4-4291-980a-f941e4cf86fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d98c45-680f-4cf6-86a6-420449590a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "SKIP_HORIZ = 20\n",
    "tr = 0.7\n",
    "m_iter = 199\n",
    "\n",
    "\n",
    "dom_to_editor = {\n",
    "    k: StyleEditor(read_weights(p), device) for k, p in weights.items() if '.pt' not in p.name \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aed12c-f2b6-4d1b-ac99-6d34aeacc288",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = uda_models['stylegan2'](\n",
    "    img_size=1024,\n",
    "    latent_size=512,\n",
    "    map_layers=8,\n",
    "    checkpoint_path='pretrained/StyleGAN2/stylegan2-ffhq-config-f.pt',\n",
    "    device=device\n",
    ").patch_layers('s_delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac9df8-ae80-4464-b50a-b3a4cdd06691",
   "metadata": {},
   "source": [
    "## Choose target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053801a-13c4-46e5-a4bb-e57fdbd2b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "\n",
    "z = [torch.randn(16, 512).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3701154-4d9a-43c6-9b46-cb16bab5ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, _ = g(z, truncation=tr)\n",
    "to_im(Resize(256)(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257c802-235f-4ea1-bf7b-3445ff247a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_lat_idx = -1\n",
    "\n",
    "z_single = [z[0].detach()[good_lat_idx].unsqueeze(0)]\n",
    "z.clear()\n",
    "s_single = g.get_s_code(z_single, truncation=tr)\n",
    "im, _ = g(s_single, is_s_code=True)\n",
    "to_im(Resize(256)(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553feaf-9cce-4689-a937-c0b232093012",
   "metadata": {},
   "source": [
    "## Morphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37adc851-183e-4691-9751-1772b546e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(list(k for k, p in weights.items() if '.pt' not in p.name)) # -- possible domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32faed9f-4a94-4958-bd41-9ce55ddf8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow = 0.6\n",
    "\n",
    "domain_order = ['pixar', 'joker', 'anime_indomain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31798f92-e1f8-4c1f-adcc-e4c395635307",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_st = [t.clone() for t in s_single]\n",
    "images = [to_im(Resize(IMAGE_SIZE)(im))]\n",
    "\n",
    "for new_domain in domain_order:\n",
    "    editor = dom_to_editor[new_domain]\n",
    "    cur_st = editor(cur_st, power=pow)\n",
    "\n",
    "    cur_im, _ = g(cur_st, is_s_code=True)\n",
    "    images.append(\n",
    "        to_im(Resize(IMAGE_SIZE)(cur_im))\n",
    "    )\n",
    "\n",
    "\n",
    "final_image = hstack_with_lines(images, SKIP_HORIZ)\n",
    "PIL.Image.fromarray(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f34352-f3f5-41f9-a209-e45402adb8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
