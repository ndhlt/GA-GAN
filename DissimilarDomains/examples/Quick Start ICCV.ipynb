{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9e3354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:21:54.272427Z",
     "start_time": "2023-12-14T21:21:22.271179Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./../')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import tabulate\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec6a79",
   "metadata": {},
   "source": [
    "For the sake of simplicity, most of the additional functions were implemented in the `nb_utils` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2243e7ab",
   "metadata": {},
   "source": [
    "# Load checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f92c0a",
   "metadata": {},
   "source": [
    "One can load an existing model using `nb_utils.load_checkpoint`. \n",
    "\n",
    "This function will return the Generator module (both trainee and ema-smoothed) as well as the initial Generator that corresponds to `--resume` CLI training option. Also, this function will parse and return the `training_options.json` and `metric-*.jsonl` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c64368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:22:01.520570Z",
     "start_time": "2023-12-14T21:22:00.738039Z"
    }
   },
   "outputs": [],
   "source": [
    "import nb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42149ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:23:21.708439Z",
     "start_time": "2023-12-14T21:23:21.665930Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "base_exp_path = '~/StyleDomain/DissimilarDomains/training-runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e4d72",
   "metadata": {},
   "source": [
    "## Obtain pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2609ec2",
   "metadata": {},
   "source": [
    "Pretrained checkpoints for this particular notebook can be found in the [file storage](https://nxt.2a2i.org/index.php/s/Q2MFXy6gpNnB4GF?path=%2F512). Download nessesary checkpoints (`\"*-afhqdog-stylegan2-*\"`) and put them into the `base_exp_path` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd85a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:23:41.996510Z",
     "start_time": "2023-12-14T21:23:22.239299Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_path = os.path.join(base_exp_path, '00066-afhqdog-stylegan2-kimg241-resumeffhq512')\n",
    "(\n",
    "    G, G_ema, # Trained Generator\n",
    "    G_base, G_ema_base, # Resume Generator\n",
    "    options, # Exact arguments that were used to train the model. See `training_options.json`\n",
    "    metrics # Metrics that were computed during training and after it using `calc_metrics.py`\n",
    ") = nb_utils.load_checkpoint(\n",
    "    exp_path=exp_path, # Path to experiment folder\n",
    "    chkpt_idx=241, # Checkpoint idx\n",
    "    device=device # GPU or CPU device to store the module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71274ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:23:43.586586Z",
     "start_time": "2023-12-14T21:23:43.542399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fid50k', [(241, 18.870261049352113)])\n",
      "('kid50k', [(241, 0.009100656791791829)])\n",
      "('fid5k', [(0, 220.4657791514723), (20, 111.77333726801315), (40, 53.77089874308393), (60, 38.42584153866183), (80, 32.829910782598134), (100, 27.963927737224857), (120, 25.11018606367864), (140, 24.039953072029498), (160, 22.23814153985294), (180, 22.246368688383946), (200, 22.25561962207952), (220, 21.17775999610977), (240, 20.72892563890517), (241, 20.321961996440223), (241, 20.504168880221464)])\n",
      "('kid5k', [(241, 0.008989224822322303)])\n"
     ]
    }
   ],
   "source": [
    "print(*metrics.items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5563938",
   "metadata": {},
   "source": [
    "# Compute metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295892a6",
   "metadata": {},
   "source": [
    "We can compute other metrics using `metric_main.calc_metric`. For example, here we compute $\\text{FID5k}$ (aka $\\text{FID}$) for the model finetuned on the **Dog** dataset with **Full** parameterization. It is worth noting that we also report $\\text{FID} = 20.3$ in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08b6b49a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:23:49.319466Z",
     "start_time": "2023-12-14T21:23:48.152172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aalanov/mnakhodnov/Domain Adaptation/StyleDomain/DissimilarDomains/examples/./../metrics/metric_utils.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  import tqdm.autonotebook as tqdm\n"
     ]
    }
   ],
   "source": [
    "from metrics import metric_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a0c1ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:34:09.095261Z",
     "start_time": "2023-12-14T21:32:02.479760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "fid5k = 20.562\n"
     ]
    }
   ],
   "source": [
    "metric = metric_main.calc_metric(\n",
    "    metric='fid5k', G=G_ema, device=device,\n",
    "    dataset_kwargs=options['training_set_kwargs']\n",
    ")\n",
    "print('{0} = {1:.3f}'.format(metric['metric'], metric['results'][metric['metric']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2548e0",
   "metadata": {},
   "source": [
    "# Generate sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d96d70",
   "metadata": {},
   "source": [
    "We can generate images from a pretrained model using the `nb_utils.generate_images` wrapper around Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b89afe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:34:21.184880Z",
     "start_time": "2023-12-14T21:34:20.490635Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_size = np.array([4, 4])\n",
    "images, _ = nb_utils.generate_images(G_ema, grid_size=grid_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7d51f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:34:26.231110Z",
     "start_time": "2023-12-14T21:34:22.415004Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(*grid_size, figsize=grid_size[::-1] * 2)\n",
    "\n",
    "nb_utils.prepare_axes(axes)\n",
    "for ax, image in zip(axes.reshape(-1), images):\n",
    "    ax.imshow(image)\n",
    "\n",
    "fig.suptitle('Uncurated Dog samples for Full parameterization')\n",
    "    \n",
    "fig.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a58138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:38:40.622808Z",
     "start_time": "2023-12-14T21:38:40.573976Z"
    }
   },
   "source": [
    "# Parameterization comparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b13b7",
   "metadata": {},
   "source": [
    "Let's compare $[\\text{Full}, \\text{SyntConv}, \\text{Affine}+, \\text{Affine}, \\text{Mapping}, \\text{AffineLight}+, \\text{StyleSpace}]$ for Dog dataset.\n",
    "\n",
    "Let's define a list of all those experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb4de291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:40:27.314256Z",
     "start_time": "2023-12-14T21:40:27.265621Z"
    }
   },
   "outputs": [],
   "source": [
    "afhqdog = {\n",
    "    'Full':         '00066-afhqdog-stylegan2-kimg241-resumeffhq512',\n",
    "    'Mapping':      '00066-afhqdog-stylegan2-kimg241-resumeffhq512-Gparts-mapping',\n",
    "    'SyntConv':     '00315-afhqdog-stylegan2-kimg241-resumeffhq512-Gparts-synt_conv,tRGB_conv',\n",
    "    'Affine':       '00068-afhqdog-stylegan2-kimg241-resumeffhq512-Gparts-synt_affine,tRGB_affine',\n",
    "    'Affine+':      '00313-afhqdog-stylegan2-glrate0.02-kimg241-resumeffhq512-Gparts-synt_affine,tRGB_affine,synt_weights_offset.b64,tRGB_weights_offset.b64-use-dom-mod-out_in_additive',\n",
    "    'StyleSpace':   '00147-afhqdog-stylegan2-glrate0.02-kimg241-resumeffhq512-Gparts-synt_offset,tRGB_offset-use-dom-mod-additive',\n",
    "    'AffineLight+': '00253-afhqdog-stylegan2-glrate0.008-kimg241-resumeffhq512-Gparts-synt_affine_weights_offset,tRGB_affine_weights_offset,synt_weights_offset.b64,tRGB_weights_offset.b64-use-dom-mod-out_in_additive,affine_out_in_5_1_additive',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9049c950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:50:03.657501Z",
     "start_time": "2023-12-14T21:49:53.464967Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Register weights offsets of shape: [512, 512, 1, 1], T: out_in_additive\n",
      "Register weights offsets of shape: [512, 512, 1, 1], T: out_in_additive\n",
      "Register weights offsets of shape: [3, 512, 1, 1], T: out_in_additive\n",
      "Register domain modulation for b4.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b4.conv. IN: 512, W: 512\n",
      "Register domain modulation for b8.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b8.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b8.conv. IN: 512, W: 512\n",
      "Register domain modulation for b16.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b16.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b16.conv. IN: 512, W: 512\n",
      "Register domain modulation for b32.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b32.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b32.conv. IN: 512, W: 512\n",
      "Register domain modulation for b64.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b64.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b64.conv. IN: 512, W: 512\n",
      "Register domain modulation for b128.torgb. IN: 512, W: 512\n",
      "Register domain modulation for b128.torgb. IN: 256, W: 512\n",
      "Register domain modulation for b128.conv. IN: 256, W: 512\n",
      "Register domain modulation for b256.torgb. IN: 256, W: 512\n",
      "Register domain modulation for b256.torgb. IN: 128, W: 512\n",
      "Register domain modulation for b256.conv. IN: 128, W: 512\n",
      "Register domain modulation for b512.torgb. IN: 128, W: 512\n",
      "Register domain modulation for b512.torgb. IN: 64, W: 512\n",
      "Register domain modulation for b512.conv. IN: 64, W: 512\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register weights offsets of shape: [512, 512, 1, 1], T: out_in_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register weights offsets of shape: [512, 512, 1, 1], T: out_in_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register weights offsets of shape: [3, 512, 1, 1], T: out_in_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 512, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 256, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 256, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 256, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 128, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 128, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 128, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 64, K: 5, IN: 512, T: affine_out_in_5_1_additive\n",
      "Register affine weights offsets. OUT: 64, K: 5, IN: 512, T: affine_out_in_5_1_additive\n"
     ]
    }
   ],
   "source": [
    "dog_models = dict()\n",
    "\n",
    "for parameterization_name, exp_suffix in afhqdog.items():\n",
    "    exp_path = os.path.join(base_exp_path, exp_suffix)\n",
    "    \n",
    "    _, G_ema, _, _, _, metrics = nb_utils.load_checkpoint(\n",
    "        exp_path=exp_path, chkpt_idx=241, device=torch.device('cpu')\n",
    "    )\n",
    "    \n",
    "    fid5k = dict(metrics['fid5k'])[241]\n",
    "    kid5k = dict(metrics['kid5k'])[241]\n",
    "    fid50k = dict(metrics['fid50k'])[241]\n",
    "    kid50k = dict(metrics['kid50k'])[241]\n",
    "\n",
    "    dog_models[parameterization_name] = (G_ema, (fid5k, kid5k, fid50k, kid50k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106642c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T21:52:33.905118Z",
     "start_time": "2023-12-14T21:52:31.785736Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_size = np.array([1, 7])\n",
    "fig, axes = plt.subplots(*grid_size, figsize=grid_size[::-1] * np.array([3, 3.2]))\n",
    "nb_utils.prepare_axes(axes)\n",
    "\n",
    "for idx, pname in enumerate(['Full', 'SyntConv', 'Affine', 'Mapping', 'Affine+', 'AffineLight+', 'StyleSpace']):\n",
    "    G_ema, _ = dog_models[pname]\n",
    "    images, _ = nb_utils.generate_images(G_ema, grid_size=1, device=device, seed=912, truncation_psi=0.9)\n",
    "    \n",
    "    axes[idx].imshow(images[0])\n",
    "    axes[idx].set_title(pname, fontdict=dict(fontsize=20, weight='bold'))\n",
    "axes[0].set_ylabel('Dog', fontdict=dict(fontsize=20, weight='bold'))\n",
    "        \n",
    "fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
